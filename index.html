<!doctype html>



  


<html class="theme-next mist use-motion">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="Soul of Light" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2">






<meta property="og:type" content="website">
<meta property="og:title" content="Soul of Light">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Soul of Light">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Soul of Light">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/">


  <title> Soul of Light </title>
</head>

<body itemscope="" itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Soul of Light</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/06/19/理解RNN/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-06-19T11:26:53+08:00" content="2019-06-19">
              2019-06-19
            </time>
          </span>

          

          
            
          

          

	  

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="理解RNN"><a href="#理解RNN" class="headerlink" title="理解RNN"></a>理解RNN</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Rnn全名Recurrent Neural Network，对时序进行了建模，能够记忆之前看到的信息。</p>
<p>举例来说：订一张从北京到上海的机票 vs 订一张从上海到北京的机票，如果直接用bow模型是无法区分这两个文本的，而使用rnn可以刻画出时序关系。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>rnn有两个输入，一个是真实输入$X^t$，一个是上一层的输入$H^{t-1}$，上一层的输入能够对上一个cell的状态进行记忆。模型将$X^t$和$H^{t-1}$进行拼接后，通过一个ffc（W）得到下一层的$H^t$，同时再通过一个FFC得到输出$Y^t$。</p>
<p>具体公式：</p>
<p>$H^t  = \sigma{(W^{hh}h^{t - 1}+ W^{hx}X^t + b)}$</p>
<p>$Y^t = softmax(W^{S}h^t)$</p>
<p>具体流程如下：</p>
<p><img src="/Users/chenhongguang01/Desktop/chg/rnn/rnn.jpeg" alt="rnn"></p>
<h4 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h4><p>计算$H^t$相关代码，将inputs 和 state拼接后，和_kernel矩阵相乘，加bias和激活函数，得到最终的输出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def call(self, inputs, state):</span><br><span class="line">  &quot;&quot;&quot;Most basic RNN: output = new_state = act(W * input + U * state + B).&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">  gate_inputs = math_ops.matmul(</span><br><span class="line">      array_ops.concat([inputs, state], 1), self._kernel)</span><br><span class="line">  gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)</span><br><span class="line">  output = self._activation(gate_inputs)</span><br><span class="line">  return output, output</span><br></pre></td></tr></table></figure>
<p>kernel相关定义：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self._kernel = self.add_variable(</span><br><span class="line">        _WEIGHTS_VARIABLE_NAME,</span><br><span class="line">        shape=[input_depth + self._num_units, self._num_units])</span><br></pre></td></tr></table></figure>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li>所有的rnn cell的权重是共享的。可以想象成输入是不动的，使rnn_cell在输入上不断的滑动。</li>
<li>rnn容易出现梯度消失和梯度爆炸，可以考虑使用lstm。</li>
<li>无法并行，可以考虑使用transformer。</li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45" target="_blank" rel="noopener">https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/ops/rnn_cell_impl.py" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/ops/rnn_cell_impl.py</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/03/01/bert_pretrainning/" itemprop="url">
                  bert pretraining源码刨析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-03-01T23:59:50+08:00" content="2019-03-01">
              2019-03-01
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope="" itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习理论/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习理论</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

	  

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Bert-Pretraining代码刨析"><a href="#Bert-Pretraining代码刨析" class="headerlink" title="Bert Pretraining代码刨析"></a>Bert Pretraining代码刨析</h3><p>本篇文章结合实际例子对bert pretraining源码进行刨析，更清晰的展现bert的整个过程。pretraining主要包括三个文件，create_pretraining_data.py, run_pretraining.py, modeling.py。</p>
<h4 id="create-pretraining-data"><a href="#create-pretraining-data" class="headerlink" title="create_pretraining_data"></a>create_pretraining_data</h4><p> 构造pretraining的训练数据，我们使用的数据(chg_data)是周杰伦的四句歌词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">素胚勾勒出青花笔锋浓转淡转淡</span><br><span class="line">瓶身描绘的牡丹一如你初妆初妆</span><br><span class="line"></span><br><span class="line">冉冉檀香透过窗心事我了然了然</span><br><span class="line">宣纸上走笔至此搁一半一半</span><br></pre></td></tr></table></figure>
<p>构造训练数据的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span> python create_pretraining_data.py \</span><br><span class="line">                   --input_file=./chg_data \</span><br><span class="line">                   --output_file=./tmp/tf_examples.tfrecord \</span><br><span class="line">                   --vocab_file=$BERT_BASE_DIR/vocab.txt \</span><br><span class="line">                   --do_lower_case=<span class="keyword">True</span> \</span><br><span class="line">                   --max_seq_length=<span class="number">128</span> \</span><br><span class="line">                   --max_predictions_per_seq=<span class="number">20</span> \</span><br><span class="line">                   --masked_lm_prob=<span class="number">0.15</span> \</span><br><span class="line">                   --random_seed=<span class="number">12345</span> \</span><br><span class="line">                   --dupe_factor=<span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>下面对create_pretraining_data的代码进行一下解析。首先，create_training_instances函数读取chg_data数据，根据空行，将数据分成两个文档，如下所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[[&apos;素&apos;, &apos;胚&apos;, &apos;勾&apos;, &apos;勒&apos;, &apos;出&apos;, &apos;青&apos;, &apos;花&apos;, &apos;笔&apos;, &apos;锋&apos;, &apos;浓&apos;, &apos;转&apos;, &apos;淡&apos;], [&apos;瓶&apos;, &apos;身&apos;, &apos;描&apos;, &apos;绘&apos;, &apos;的&apos;, &apos;牡&apos;, &apos;丹&apos;, &apos;一&apos;, &apos;如&apos;, &apos;你&apos;, &apos;初&apos;, &apos;妆&apos;]], [[&apos;冉&apos;, &apos;冉&apos;,     &apos;檀&apos;, &apos;香&apos;, &apos;透&apos;, &apos;过&apos;, &apos;窗&apos;, &apos;心&apos;, &apos;事&apos;, &apos;我&apos;, &apos;了&apos;, &apos;然&apos;], [&apos;宣&apos;, &apos;纸&apos;, &apos;上&apos;, &apos;走&apos;, &apos;笔&apos;, &apos;至&apos;, &apos;此&apos;, &apos;搁&apos;, &apos;一&apos;, &apos;半&apos;]]]</span><br></pre></td></tr></table></figure>
<p>create_training_instances中的关键代码如下，功能是将数据进行拆分，构造sentence／next_sentence对</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造多组first_sen &amp; next_sen对，并对数据进行mask</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(dupe_factor):</span><br><span class="line">  <span class="keyword">for</span> document_index <span class="keyword">in</span> range(len(all_documents)):</span><br><span class="line">    instances.extend(</span><br><span class="line">        create_instances_from_document(</span><br><span class="line">            all_documents, document_index, max_seq_length, short_seq_prob,</span><br><span class="line">            masked_lm_prob, max_predictions_per_seq, vocab_words, rng))</span><br></pre></td></tr></table></figure>
<p>最终生成的数据instance如下，并将数据写入tf_examples.tfrecord，用于之后的pertaining。当然这是命中80%概率进行mask的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tokens : [CLS] [MASK] 胚 勾 勒 出 青 花 [MASK] 锋 浓 转 淡 [SEP] 瓶 身 描 绘 的 牡 丹 一 如 [MASK] 初 [MASK] [SEP]</span><br><span class="line">segment_ids :  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1</span><br><span class="line">is_random_next : False</span><br><span class="line">masked_lm_positions: 1 8 23 25</span><br><span class="line">masked_lm_labels: 素 笔 你 妆</span><br></pre></td></tr></table></figure>
<p>tf_record格式的数据如下，需要注意的是next_sentence_labels中0表示是next_sentence, 1表示不是next_sentence。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tokens: [CLS] [MASK] 胚 勾 勒 出 青 花 [MASK] 锋 浓 转 淡 [SEP] 瓶 身 描 绘 的 牡 丹 一 如 [MASK] 初 [MASK] [SEP]</span><br><span class="line">input_ids: 101 103 5524 1256 1239 1139 7471 5709 103 7226 3849 6760 3909 102 4486 6716 2989 5313 4638 4285 710 671 1963 103 1159 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">intput_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">masked_lm_positions: 1 8 23 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">masked_lm_ids: 5162 5011 872 1966 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span><br><span class="line">next_sentence_labels: 0</span><br></pre></td></tr></table></figure>
<h4 id="run-pretraining"><a href="#run-pretraining" class="headerlink" title="run_pretraining"></a>run_pretraining</h4><p>主要包括两个loss，一个是get_masked_lm_output用于预测mask后的词，一个是get_next_sentence_output用来预测next_sen的概率。最终的loss是这两个loss的和，用来作为优化目标。</p>
<h4 id="modeling"><a href="#modeling" class="headerlink" title="modeling"></a>modeling</h4><p>该模块完整实现了transformer的encoder部分的代码，实现了multi-head attention结构。</p>
<p>最终的输出包括get_sequence_output返回所有token的隐层表示，get_pooled_output返回[CLS]对应的隐层表示。</p>
<p>下面这段代码要表达的是，[CLS]位置不是直接使用encode的输出，而是又增加了一个hidden layer，作为最终[CLS]的输出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">with tf.variable_scope(&quot;pooler&quot;):</span><br><span class="line"># We &quot;pool&quot; the model by simply taking the hidden state corresponding</span><br><span class="line"># to the first token. We assume that this has been pre-trained</span><br><span class="line">    first_token_tensor = tf.squeeze(self.sequence_output[:, 0:1, :], axis=1)</span><br><span class="line">    self.pooled_output = tf.layers.dense(</span><br><span class="line">            first_token_tensor,</span><br><span class="line">            config.hidden_size,</span><br><span class="line">            activation=tf.tanh,</span><br><span class="line">            kernel_initializer=create_initializer(config.initializer_range))</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>看论文的同时还要去看下源代码来加深理解，更需要我们跑一些case来验证我们的想法。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/02/05/tensorflow/" itemprop="url">
                  tensorflow 常用命令
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-02-05T23:59:50+08:00" content="2019-02-05">
              2019-02-05
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope="" itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习理论/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习理论</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

	  

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ol>
<li><p>查看tensorboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在estimator模式下查看tensorboard</span><br><span class="line">tensorboard --logdir model_dir --host 0.0.0.0 --port 8888</span><br></pre></td></tr></table></figure>
</li>
<li><p>指定gpu</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;3&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看gpu使用情况 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看tensorflow版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看cuda版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/version.txt</span><br><span class="line">CUDA Version 8.0.44</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li><a href="https://github.com/c00h00g/tf_chg/" target="_blank" rel="noopener">https://github.com/c00h00g/tf_chg/</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/02/01/理解LSTM/" itemprop="url">
                  理解LSTM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-02-01T23:59:50+08:00" content="2019-02-01">
              2019-02-01
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope="" itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习理论/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习理论</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

	  

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>rnn可以解决时序问题，但是容易出现梯度爆炸／梯度爆炸的问题，当文本较长的时候，效果并不好。LSTM，是Long Short-Term Memory，中文可以理解成比较长的Short-Term Memory，因为当文本非常长的时候，效果也会有问题（可以通过加入attention方式解决）。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><h4 id="具体网络结构"><a href="#具体网络结构" class="headerlink" title="具体网络结构"></a>具体网络结构</h4><p>下面这张图，是目前我看到的最清晰的描述LSTM网络结构的图片，使用一个实例描述了整个过程。其中S表示该神经元使用sigmoid激活函数触发，T表示该神经元使用tanh函数触发。输入的纬度是3，隐层的纬度是2。</p>
<p><img src="/images/lstm_cell.png" alt="lstm_cell"></p>
<h3 id="抽象网络结构"><a href="#抽象网络结构" class="headerlink" title="抽象网络结构"></a>抽象网络结构</h3><p>下面这张图画的也很不错，从抽象的角度定义了LSTM，可以对比来看，一个是抽象，一个是实例。</p>
<p><img src="/images/lstm_cell_con.png" alt="lstm_cell_con"></p>
<p><img src="/images/lstm_single_cell.png" alt="lstm_single_cell"></p>
<p>几个公式：</p>
<ol>
<li>遗忘门：$f_t = \sigma(W_f  [h_{t-1}, x_t] + b_f)$</li>
<li>输入门：$i_t = \sigma(W_i[h_{t-1}, x_t] + b_i)$</li>
<li>$\tilde{C_t} = tanh(W_C [h_{t-1}, x_t] + b_C)$</li>
<li>$C_t = f_t <em> C_{t - 1} + i_t </em> \tilde {C_t}$</li>
<li>$O_t = \sigma(W_o[h_{t-1}, x_t] + b_o)$</li>
<li>$h_t = o_t * tanh(C_t)$</li>
</ol>
<h3 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h3><p>下面代码构造网络参数，我们可以看出来_kernel用来存储模型参数，可以看出来存储了4倍的参数，因为我们有四个FFC网络。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def build(self, inputs_shape):</span><br><span class="line">    if inputs_shape[-1] is None:</span><br><span class="line">      raise ValueError(&quot;Expected inputs.shape[-1] to be known, saw shape: %s&quot;</span><br><span class="line">                       % str(inputs_shape))</span><br><span class="line"></span><br><span class="line">    input_depth = inputs_shape[-1]</span><br><span class="line">    h_depth = self._num_units</span><br><span class="line">    self._kernel = self.add_variable(</span><br><span class="line">        _WEIGHTS_VARIABLE_NAME,</span><br><span class="line">        shape=[input_depth + h_depth, 4 * self._num_units])</span><br><span class="line">    self._bias = self.add_variable(</span><br><span class="line">        _BIAS_VARIABLE_NAME,</span><br><span class="line">        shape=[4 * self._num_units],</span><br><span class="line">        initializer=init_ops.zeros_initializer(dtype=self.dtype))</span><br><span class="line"></span><br><span class="line">    self.built = True</span><br></pre></td></tr></table></figure>
<p>下面这段代码是实际的计算过程，需要注意的是，每次更新，需要返回两个状态$h_t$和$C_t$。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">def call(self, inputs, state):</span><br><span class="line">    &quot;&quot;&quot;Long short-term memory cell (LSTM).</span><br><span class="line">    Args:</span><br><span class="line">      inputs: `2-D` tensor with shape `[batch_size, input_size]`.</span><br><span class="line">      state: An `LSTMStateTuple` of state tensors, each shaped</span><br><span class="line">        `[batch_size, num_units]`, if `state_is_tuple` has been set to</span><br><span class="line">        `True`.  Otherwise, a `Tensor` shaped</span><br><span class="line">        `[batch_size, 2 * num_units]`.</span><br><span class="line">    Returns:</span><br><span class="line">      A pair containing the new hidden state, and the new state (either a</span><br><span class="line">        `LSTMStateTuple` or a concatenated state, depending on</span><br><span class="line">        `state_is_tuple`).</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    sigmoid = math_ops.sigmoid</span><br><span class="line">    one = constant_op.constant(1, dtype=dtypes.int32)</span><br><span class="line">    # Parameters of gates are concatenated into one multiply for efficiency.</span><br><span class="line">    if self._state_is_tuple:</span><br><span class="line">      c, h = state</span><br><span class="line">    else:</span><br><span class="line">      c, h = array_ops.split(value=state, num_or_size_splits=2, axis=one)</span><br><span class="line"></span><br><span class="line">    gate_inputs = math_ops.matmul(</span><br><span class="line">        array_ops.concat([inputs, h], 1), self._kernel)</span><br><span class="line">    gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)</span><br><span class="line"></span><br><span class="line">    # i = input_gate, j = new_input, f = forget_gate, o = output_gate</span><br><span class="line">    i, j, f, o = array_ops.split(</span><br><span class="line">        value=gate_inputs, num_or_size_splits=4, axis=one)</span><br><span class="line"></span><br><span class="line">    forget_bias_tensor = constant_op.constant(self._forget_bias, dtype=f.dtype)</span><br><span class="line">    # Note that using `add` and `multiply` instead of `+` and `*` gives a</span><br><span class="line">    # performance improvement. So using those at the cost of readability.</span><br><span class="line">    add = math_ops.add</span><br><span class="line">    multiply = math_ops.multiply</span><br><span class="line">    new_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))),</span><br><span class="line">                multiply(sigmoid(i), self._activation(j)))</span><br><span class="line">    new_h = multiply(self._activation(new_c), sigmoid(o))</span><br><span class="line"></span><br><span class="line">    if self._state_is_tuple:</span><br><span class="line">      new_state = LSTMStateTuple(new_c, new_h)</span><br><span class="line">    else:</span><br><span class="line">      new_state = array_ops.concat([new_c, new_h], 1)</span><br><span class="line">    return new_h, new_state</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45" target="_blank" rel="noopener">https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/12/01/Bert 模型部署/" itemprop="url">
                  bert模型部署初探
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-12-01T23:59:50+08:00" content="2018-12-01">
              2018-12-01
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope="" itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习理论/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习理论</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

	  

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Bert-模型部署"><a href="#Bert-模型部署" class="headerlink" title="Bert 模型部署"></a>Bert 模型部署</h3><p>最近在研究google的bert相关知识，使用fine-tune方法训练了一个模型，但是看效果比较麻烦，每次都要重新load模型导致效率非常低下。<br>因此，参考网上以及同事的思路，设计了一套通用的bert model查看效果的工具。</p>
<h4 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h4><ol>
<li><p>如何产出模型文件？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">estimator._export_to_tpu = <span class="keyword">False</span></span><br><span class="line">estimator.export_savedmodel(<span class="string">"./export/"</span>, serving_input_fn)</span><br></pre></td></tr></table></figure>
</li>
<li><p>如何避免重复加载？</p>
<p>我们通过graph建立了sess，启动一个web应用，将sess保存在内存中，请求来的时候，直接使用sess进行predict，export_dir 是模型的路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line">self.graph_predict = tf.Graph()</span><br><span class="line">self.sess = tf.Session(graph = self.graph_predict)</span><br><span class="line">tf.saved_model.loader.load(self.sess, [tag_constants.SERVING], export_dir)</span><br></pre></td></tr></table></figure>
</li>
<li><p>如何结合web框架？</p>
<p>本次使用的是flask，为什么要使用flask，因为tf使用的是python，使用flask的话，可以直接将sess的实例保存在内存中，每次请求来的时候进行预测。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> predictor <span class="keyword">import</span> Predictor</span><br><span class="line">one_predictor = Predictor(args)</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello_world</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Hello World!'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/test', methods=['GET', 'POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">'POST'</span>:</span><br><span class="line">        query = (request.form.get(<span class="string">'se_query'</span>).strip())</span><br><span class="line">        result = one_predictor.predict_query(query)</span><br><span class="line">        <span class="keyword">return</span> render_template(<span class="string">'test.html'</span>, result)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    server = pywsgi.WSGIServer((<span class="string">'0.0.0.0'</span>, <span class="number">8001</span>), app)</span><br><span class="line">    server.serve_forever()</span><br></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>使用flask封装bert fine-tune后的模型，极大的提高了策略调研的效率，还是要多思考，多尝试，多看tf的api相关文档。</p>
<h4 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h4><ol>
<li><a href="https://github.com/c00h00g/bert_app_serving" target="_blank" rel="noopener">https://github.com/c00h00g/bert_app_serving</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Soulight">
          <p class="site-author-name" itemprop="name">Soulight</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">36</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/c00h00g" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Soulight</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

<span id="busuanzi_container_site_uv">
    &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

  k

</body>
</html>
